
services:
  fastapi:
    build: .
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    ports:
      - "8000:8000"
    env_file:
      - .env
    volumes:
      - ./:/app     # for hot reload and local nlp model
    depends_on:
      - postgres
      - redis
      - qdrant

  celery:
    build: .
    command: watchmedo auto-restart --directory=./ --pattern="*.py" --recursive -- celery -A celery_tasks.pipeline worker --loglevel=info
    env_file:
      - .env
    depends_on:
      - fastapi
      - postgres
      - redis
      - qdrant

  celery-beat:
    build: .
    command: watchmedo auto-restart --directory=./ --pattern="*.py" --recursive -- celery -A celery_tasks.pipeline beat --loglevel=info

    env_file:
      - .env
    depends_on:
      - fastapi
      - postgres
      - redis
      - qdrant

  redis:
    image: redis:7.2
    ports:
      - "6379:6379"

  postgres:
    image: postgres:15
    restart: always
    env_file:
      - .env
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data


  qdrant:
    image: qdrant/qdrant:latest
    restart: always
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage

  embedding:
    build: .
    command: uvicorn llm.embedding_api:app --host 0.0.0.0 --port 9000
    ports:
      - "9000:9000"
    env_file:
      - .env
    volumes:
      - ./:/app
    depends_on:
      - redis
      - qdrant
    

volumes:
  pgdata:
  qdrant_data:
